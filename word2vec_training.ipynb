{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import re\n",
    "from nltk import word_tokenize\n",
    "from nltk import tokenize\n",
    "import unicodedata\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones utiles"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Leer pdf a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pdf_to_txt(path):\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = StringIO()\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(rsrcmgr, retstr, laparams=laparams)\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    \n",
    "    fp = open(path, 'rb')\n",
    "    iterPDF = iter(PDFPage.get_pages(fp, set(), maxpages=0, password=\"\",caching=True, check_extractable=True))\n",
    "    next(iterPDF)\n",
    "\n",
    "    for page in iterPDF:\n",
    "        interpreter.process_page(page)\n",
    "        text = retstr.getvalue()\n",
    "\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Preprocesar texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower() \n",
    "    \n",
    "    text = text.replace('.','PUNTOSEGUIDO')\n",
    "    #eliminar signos de puntuacion\n",
    "    #words = [word for word in word_tokenize(text) if re.search(\"\\w\", word)]\n",
    "    \n",
    "    #eliminar numeros\n",
    "    text = ''.join([word for word in text if not word.isdigit()])\n",
    "    \n",
    "    #eliminar caracteres unicode\n",
    "    text = unicodedata.normalize(\"NFKD\", text).encode(\"ascii\",\"ignore\").decode(\"ascii\")\n",
    "    text = re.sub(r'[\\x00-\\x08\\x0b\\x0c\\x0e-\\x1f\\x7f-\\xff]', '', text)\n",
    "    \n",
    "    #reemplazar espacios consecutivos por uno solo\n",
    "    #text = re.compile(r\"\\s+\").sub(\" \", text).strip()\n",
    "    \n",
    "    #eliminar algunas stop words particulares de los documentos\n",
    "    special_stop_words = ['cuestionario','preguntas','respuestas','responder','trabajo','practico','marketing','digital','cuatrimestre','pagina']\n",
    "    text  = ' '.join([word.lower() for word in re.split(\"\\W+\",text) if word.lower() not in special_stop_words])\n",
    "    \n",
    "    #eliminar palabras de menos de 1 letra que no sea vocal\n",
    "    text  = ' '.join([word.lower() for word in re.split(\"\\W+\",text) if len(word)>1 or word in ['a','e','i','o','u']])\n",
    "    \n",
    "    text = text.replace('puntoseguido','.')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Chequear las palabras de una oracion que conoce el modelo entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_in_vocabulary(sentence):\n",
    "    words = tokenize.word_tokenize(sentence)\n",
    "    return [word for word in words if word in trained_model.wv.vocab ]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Si una palabra es considerada como una palabra con la que suelen empezar las preguntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_a_question_word(word):\n",
    "    return word in ['cuales','que','de','explique','desarrolle','describa','¿']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar modelo entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_modelo(path):\n",
    "    return KeyedVectors.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = cargar_modelo (\"modelo_entrenado_dataset_UTN.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = cargar_modelo (\"complete.kv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_model(doc1,doc2,nlp):\n",
    "    sentences1 = tokenize.sent_tokenize(doc1)\n",
    "    sentences2 = tokenize.sent_tokenize(doc2)\n",
    "    \n",
    "    for sentence1 in sentences1:\n",
    "        for sentence2 in sentences2:\n",
    "            \n",
    "            words1 = tokenize.word_tokenize(sentence1)\n",
    "            words2 = tokenize.word_tokenize(sentence2)            \n",
    "            \n",
    "            if(len(words1)>5 and len(words2)>5):\n",
    "                sentence = \" \".join([word for word in words1 if word not in stopwords.words('spanish')])\n",
    "                sentencee = \" \".join([word for word in words2 if word not in stopwords.words('spanish')])\n",
    "                \n",
    "                similaridad = nlp(sentence).similarity(nlp(sentencee))\n",
    "                \n",
    "                if similaridad > 0.9 and not is_a_question_word(words1[0]) and not is_a_question_word(words2[0]):\n",
    "                    print(\"POSIBLE PLAGIO DETECTADO \\n ORACION1: \" +  sentence1 + \"\\n ORACION2: \" + sentence2 + \"\\n SIMILITUD: \" + str(similaridad))\n",
    "                    print('--------------------O-----------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chequear_plagio_similitudes(doc1,doc2,file):\n",
    "    sentences1 = tokenize.sent_tokenize(doc1)\n",
    "    sentences2 = tokenize.sent_tokenize(doc2)\n",
    "    cant_similitudes = 0\n",
    "    plagios=\"\"\n",
    "    \n",
    "    for sentence1 in sentences1:\n",
    "        words1 = is_in_vocabulary(sentence1)\n",
    "        print(\"hola\")\n",
    "        if(len(words1)>3):\n",
    "            for sentence2 in sentences2:\n",
    "                words2 = is_in_vocabulary(sentence2)\n",
    "                if(len(words2)>3):\n",
    "\n",
    "                    for word1 in words1:\n",
    "                        cant_similitudes = 0\n",
    "                        for word2 in words2:\n",
    "                            if(word2 in trained_model.most_similar(word1,topn=30)):\n",
    "                                cant_similitudes = cant_similitudes + 1\n",
    "\n",
    "                if cant_similitudes >= 1 and not is_a_question_word(words1[0]) and not is_a_question_word(words2[0]):\n",
    "                    print(\"POSIBLE PLAGIO DETECTADO \\n ORACION1: \" +  sentence1 + \"\\n ORACION2: \" + sentence2 + \"\\n SIMILITUD: \" + str(similaridad))\n",
    "                    print('--------------------O-----------------')\n",
    "        \n",
    "    return plagios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chequear_plagio(doc1,doc2,file):\n",
    "    print(doc1)\n",
    "    \n",
    "    sentences1 = tokenize.sent_tokenize(doc1)\n",
    "    sentences2 = tokenize.sent_tokenize(doc2)\n",
    "    \n",
    "    plagios = \"\"\n",
    "    \n",
    "    for sentence1 in sentences1:\n",
    "        for sentence2 in sentences2:\n",
    "            \n",
    "            similaridad = 0\n",
    "            \n",
    "            words1 = is_in_vocabulary(sentence1)\n",
    "            words2 = is_in_vocabulary(sentence2)\n",
    "            print(sentence1)\n",
    "            if(len(words1)>5 and len(words2)>5):\n",
    "                similaridad = trained_model.n_similarity(words1,words2)\n",
    "                print(similaridad)\n",
    "                if similaridad > 0.1 and not is_a_question_word(words1[0]) and not is_a_question_word(words2[0]):\n",
    "                    plagios = plagios + '\\n--------------------O----------------- \\n TP PLAGIADO: '  + file  +  \"\\n ORACION1: \" +  sentence1 + \"\\n ORACION2: \" + sentence2 + \"\\n SIMILITUD: \" + str(similaridad)\n",
    "            #        print(\"POSIBLE PLAGIO DETECTADO \\n ORACION1: \" +  sentence1 + \"\\n ORACION2: \" + sentence2 + \"\\n SIMILITUD: \" + str(similaridad))\n",
    "          #          print('--------------------O-----------------')\n",
    "        \n",
    "        return plagios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hola\n",
      "hola\n"
     ]
    }
   ],
   "source": [
    "pdf_to_check = preprocess_text(convert_pdf_to_txt(\"D:\\LaboratoriosNLP\\TP NLP\\Input\\SCHMID TP N°3 Experience Economy.pdf\"))\n",
    "directorio_data_sets = r'D:\\TP NLP\\DataSet'\n",
    "doc = preprocess_text(convert_pdf_to_txt(\"D:\\TP NLP\\DataSet\\K5071 - Matias David Choren - TP N°5 Rifkin (1).pdf\"))\n",
    "\n",
    "chequear_plagio_similitudes(doc,pdf_to_check,\"Rikfin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matias david choren . a .puede describir el vinculo entre las leyes de la termodinamica de newton la factura entropica .podria caracterizar la primera segunda revolucion industrial al decir de rifkin que inventos son las metaforas de cada infraestructura en cada una de esas etapas .que dice rifkin que la internet de las cosas iot le aportara a la ra revolucion industrial .que entiende rifkin por una produccion abierta distribuida colaborativa la innovacion bajo el procomun .que ejemplos actuales de procomunes se le ocurren describa. que limites le ve ud. a los procomunes como forma de produccion .a la sociedad economia del conocimiento entendida como la ra revolucion de rifkin cual de las infraestructuras claves estaria mas demorada porque que estaria faltando .como funcionaria o se garantizaria comparado con el sistema capitalista .acorde su lectura de rifkin las clases de prince para el estadio actual de la economia elija uno de estos apellidos justifique brevemente. e. colaborativa e. de la informacion e. del conocimiento e. e. sustentable e. intangible o sin peso e. sin friccion. nota formato que esta guia. las no deberan superar en su conjunto a paginas del mismo de matias david choren . . puede describir el vinculo entre las leyes de la termodinamica de newton la factura entropica la factura entropica se refiere al impacto ecologico que ha tenido nuestra economia sobre el medio ambiente. el autor hace mencion que en ninguna actividad economica se produce un aumento neto de la energia. es decir para poder haber producido algo se tuvo que haber consumido algo anteriormente. esto se condice con la primera ley de la termodinamica que expresa que la energia total en el universo es constante la entropia total aumenta continuamente. a su vez una vez producido el bien no se puede hacer el proceso inverso para deshacer el bien recuperar la materia prima. esto lo expresa la segunda ley de la termodinamica la energia fluye de lo caliente a lo frio de lo concentrado a lo disperso del orden al caos aumento unidireccional de la entropia . si no se asume que la actividad economica esta fuertemente ligada a la factura entropica nuestro modelo economico podria ser irreversiblemente perjudicial para la vida en el planeta. . podria caracterizar la primera segunda revolucion industrial al decir de rifkin que inventos son las metaforas de cada infraestructura en cada una de esas etapas segun el autor las primeras dos revoluciones industriales crearon nuevas plataformas tecnologicas maquina a vapor telegrafo ferrocarriles en la primera motores de combustion interna autos aviones comunicaciones por ondas electromagneticas las muchas durante la segunda que a su vez ayudaron a separar acotar interdependencias ecologicas de la tierra para intercambio comercial el beneficio personal. las plataformas tecnologicas de la primera segunda revolucion industrial estaban centralizadas sometidas a un control jerarquizado su explotacion estaba basada en la idea de que los recursos de la tierra estan para el servicio de la personas el lucro.. estas primeras dos revoluciones industriales realizaron grandes cambios en la produccion de los bienes pero estos cambios no fueron solo por las nuevas tecnologias los procesos utilizados sino tambien por la energia que permitia que estos avances pudieran ser explotados. . que dice rifkin que la internet de las cosas iot le aportara a la ra revolucion industrial el autor afirma que la iot aumentara la productividad de manera tal de llegar a un coste marginal cero a la hora producir bienes servicios. esto traeria aparejado una importante reduccion en los beneficios empresariales asi como en la relevancia de los derechos de propiedad abriendo paso hacia una economia de la abundancia dejando atras al modelo anterior de economia de la escasez. de matias david choren . . que entiende rifkin por una produccion abierta distribuida colaborativa segun rifkin la produccion abierta distribuida colaborativa es la explotacion del potencial tecnologico para generar transmitir informacion asi como la utilizacion de la colaborar de manera tal que las personas moda social de compartir interconectadamente puedan resolver problemas hacerse de productos o servicios a costos muy bajos costo marginal casi cero al eliminar los intermediarios tradicionales. . que ejemplos actuales de procomunes se le ocurren describa. que limites le ve ud. a los procomunes como forma de produccion ejemplos de procomunes actuales en las ciudades pueden ser la infraestructura vial. cada uno utiliza los caminos calles para objetivos propios. sin embargo la sobreexplotacion de este recurso ocasiona atrasos embotellamientos contaminacion. otro ejemplo es el medio ambiente. el aire o los recursos hidricos de una ciudad dependen de su correcta razonable utilizacion para poder seguir siendo utilizables. el principal limitacion de los procomunes como forma de produccion es la avaricia de los individuos la inhabilidad de la sociedad como un todo de proteger los mismos de la sobreexplotacion depredacion por parte un individuo de manera tal que no se pueda acceder a este recurso de manera razonable e igualitariamente. . a la sociedad economia del conocimiento entendida como la ra revolucion de rifkin cual de las infraestructuras claves estaria mas demorada porque que estaria faltando la infraestructura clave que estaria mas relegada es la infraestructura energetica ya que estaria faltando una manera de producir energia de manera barata desconcentrada masiva. esto se debe a que nuestra estructura energetica actual sigue dependiendo de los combustibles fosiles todavia no se ha dado la conversion masiva hacia las energias verdes o renovables. . como funcionaria o se garantizaria la innovacion bajo el procomun comparado con el sistema capitalista el sistema capitalista argumenta que si todo fuese gratuito no habria motivacion externa para innovar crear nuevos productos. sin embargo el procomun alega que los individuos estan motivados por fines mas alla de lo monetario impulsados por fomentar el bienestar social general.. . acorde su lectura de rifkin las clases de prince para el estadio actual de la economia elija uno de estos apellidos justifique brevemente. economia de la informacion. el estadio actual se caracteriza por la habilidad de poder compartir acceder a grandes cantidades de informacion de manera casi instantanea. todavia falta mucho para masificar la colaboracion falta desarrollo para poder convertir la informacion en conocimiento. dependemos de una matriz de produccion fisica nuestro actual modelo dista todavia de ser sustentable. de\n"
     ]
    }
   ],
   "source": [
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = preprocess_text(convert_pdf_to_txt(directorio_data_sets + r'\\TP3PabloPallocchi.pdf'))\n",
    "chequear_plagio(doc,pdf_to_check,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import es_core_news_sm\n",
    "nlp = es_core_news_sm.load()\n",
    "spacy_model(doc,pdf_to_check,nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plagio:\n",
    "    def __init__(self,oracion1,oracion2,cosineDistance,doc1,doc2):\n",
    "        self.oracion1 = oracion1\n",
    "        self.oracion2 = oracion2\n",
    "        self.cosineDistance = str(cosineDistance)\n",
    "        self.documento1 = doc1\n",
    "        self.documento2 = doc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plagios.to_csv(\"plagios.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lab1-NLP]",
   "language": "python",
   "name": "conda-env-lab1-NLP-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
